{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP 527: Implementing the k-means clustering algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In the assignment, you are required to cluster words belonging to four categories: animals, countries, fruits and veggies. The words are arranged into four different files. The first entry in each line is a word followed by 300 features (word embedding) describing the meaning of that word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    " \n",
    "> (1) Implement the k-means clustering algorithm with Euclidean distance to cluster the instances into k clusters. (30 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import scipy\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word():\n",
    "    \"\"\"Object class for a categorized word with data vector.\"\"\"\n",
    "    \n",
    "    def __init__(self, name, vector, category):\n",
    "        self.name = name\n",
    "        self.vector = vector\n",
    "        self.category = category\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'word: {self.name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(list_of_filenames):\n",
    "    \"\"\"Read in data.\"\"\"\n",
    "\n",
    "    collection = []\n",
    "\n",
    "    for filename in list_of_filenames:\n",
    "        data = open(filename).read().split('\\n')[:-1]\n",
    "\n",
    "        for word_data in data:\n",
    "            split = word_data.split(' ')\n",
    "            name = split[0]\n",
    "            raw_list = split[1:]\n",
    "\n",
    "            floats = []\n",
    "            for x_string in raw_list:\n",
    "                floats.append(float(x_string))\n",
    "\n",
    "            vector = np.array(floats)\n",
    "\n",
    "            collection.append( Word(name, vector, filename))\n",
    "\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329\n"
     ]
    }
   ],
   "source": [
    "categories = ['animals', 'countries', 'fruits', 'veggies']\n",
    "words = read_data(categories)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "animals 50\n",
      "countries 161\n",
      "fruits 58\n",
      "veggies 60\n"
     ]
    }
   ],
   "source": [
    "category = {}\n",
    "for c in categories:\n",
    "    category[c] = []\n",
    "    for w in words:\n",
    "        if w.category == c:\n",
    "            category[c].append(w)\n",
    "    print(c, len(category[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words:\n",
    "    if w.vector.shape != words[0].vector.shape:\n",
    "        print('ERROR', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(u, v):\n",
    "    \"\"\"Return Euclidean distance between two np.array vectors.\"\"\"\n",
    "\n",
    "    return np.sqrt( (u - v).dot( u - v ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(u, v):\n",
    "    \"\"\"Return Manhattan distance between two np.array vectors.\"\"\"\n",
    "\n",
    "    w = u - v\n",
    "    distance = 0\n",
    "    for x in w:\n",
    "        distance += abs(x)\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(u, v):\n",
    "    \"\"\"Return Cosine similarity of two np.array vectors.\"\"\"\n",
    "    \n",
    "    return u.dot(v)/( np.sqrt(u.dot(u)) * np.sqrt(v.dot(v)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    \"\"\"Return normalized vectors (ie. parallel vector with unit magnitude).\"\"\"\n",
    "    \n",
    "    normalized_data = []\n",
    "    \n",
    "    for d in data:\n",
    "        normalized_vector = d.vector / np.sqrt( d.vector.dot(d.vector) )\n",
    "        normalized_data.append(Word(d.name, normalized_vector, d.category))\n",
    "    \n",
    "        \n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = euclidean_distance, manhattan_distance, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142135623730951\n",
      "2\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for metric in metrics:\n",
    "    print(metric(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans():\n",
    "    \n",
    "    def __init__(\n",
    "                self, \n",
    "                k = 4, \n",
    "                data = words, \n",
    "                metric = euclidean_distance, \n",
    "                normalize = False, \n",
    "                max_iterations = 10**10, \n",
    "                seed = None,\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Initialize KMeans Model.\n",
    "        \n",
    "        Args:\n",
    "            k (int): number of clusters to divide data into.\n",
    "            data (list): list of dicts which must each include\n",
    "                the keys 'name' (string) and 'vector' (np.ndarray).\n",
    "            metric (function): to measure distance between points.\n",
    "            normalize (Boolean): whether or not to normalize vectors.\n",
    "            iterations (int): when to stop if no convergence.\n",
    "            seed (int): for reproducible (pseudo-)randomness.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.k = k\n",
    "        \n",
    "        if normalize:\n",
    "            self.data = normalize(data)\n",
    "        else:\n",
    "            self.data = data\n",
    "        \n",
    "        self.metric = metric\n",
    "        \n",
    "        self._upperbound, self._lowerbound = self._bounds()\n",
    "        \n",
    "        if seed:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        # we track centroid positions and cluster labels in nested dicts,\n",
    "        # of the form dict_name[centroid_number][iteration_number]\n",
    "        self._centroid = {}\n",
    "        for centroid_number in range(k):\n",
    "            self._centroid[centroid_number] = {}\n",
    "        \n",
    "        self._cluster = {}\n",
    "        for centroid_number in range(k):\n",
    "            self._cluster[centroid_number] = {}\n",
    "\n",
    "        # we record cluster labels explicitly as well\n",
    "        self._label = {}\n",
    "        for datum in data:\n",
    "            self._label[datum.name] = {}\n",
    "        \n",
    "        self.max_iterations = max_iterations\n",
    "        self._iteration = 0\n",
    "        self._iterate()\n",
    "        \n",
    "        \n",
    "    def _bounds(self):\n",
    "        \"\"\"Find upper and lower bounds of data space.\"\"\"\n",
    "        \n",
    "        upper = np.zeros(len(words[0].vector))\n",
    "        lower = np.zeros(len(words[0].vector))\n",
    "        \n",
    "        for d in self.data:\n",
    "            for i, x in enumerate(d.vector):\n",
    "                upper[i] = max(upper[i], x)\n",
    "                lower[i] = min(lower[i], x)\n",
    "        \n",
    "        return upper, lower\n",
    "    \n",
    "    \n",
    "    def _start(self):\n",
    "        \"\"\"Generate starting positions for k centroids.\"\"\"\n",
    "        \n",
    "        for centroid_number in range(self.k):\n",
    "            self._centroid[centroid_number][0] = self._lowerbound \\\n",
    "                + np.random.random() * (self._upperbound - self._lowerbound)\n",
    "    \n",
    "    \n",
    "    def _classify(self):\n",
    "        \"\"\"Assign each data point to cluster of nearest centroid.\"\"\"\n",
    "        \n",
    "        for centroid_number in range(self.k):\n",
    "            self._cluster[centroid_number][self._iteration] = []\n",
    "        \n",
    "        for d in self.data:\n",
    "            distances = []\n",
    "            \n",
    "            for centroid_number in range(self.k):\n",
    "                distances.append(self.metric(d.vector, self._centroid[centroid_number][self._iteration]))\n",
    "            \n",
    "            closest_centroid = np.argmin(distances)\n",
    "            \n",
    "            self._cluster[closest_centroid][self._iteration].append(d)\n",
    "            self._label[d.name][self._iteration] = closest_centroid\n",
    "\n",
    "            \n",
    "    def _reposition(self):\n",
    "        \"\"\"Move centroids to mean of each cluster.\"\"\"\n",
    "        \n",
    "        for centroid_number in range(self.k):\n",
    "            \n",
    "            clustered = self._cluster[centroid_number][self._iteration - 1]\n",
    "            \n",
    "            if len(clustered) > 0:\n",
    "                vector_sum = np.zeros(len(clustered[0].vector))\n",
    "                \n",
    "                for datum in clustered:\n",
    "                    vector_sum += datum.vector\n",
    "\n",
    "                cluster_mean = vector_sum / len(clustered)\n",
    "\n",
    "                self._centroid[centroid_number][self._iteration] = cluster_mean\n",
    "\n",
    "            else:\n",
    "                # nothing assigned to this cluster\n",
    "                pass\n",
    "            \n",
    "            \n",
    "    def _stop():\n",
    "        \"\"\"Stop iterating and return results.\"\"\"\n",
    "        \n",
    "        return 'done'\n",
    "    \n",
    "    def _iterate(self):\n",
    "        \"\"\"Position centroids and classify data by nearest centroid.\"\"\"\n",
    "        \n",
    "        if self._iteration == 0:\n",
    "            self._start()\n",
    "        else:\n",
    "            self._reposition()\n",
    "        \n",
    "        if self._iteration == self.max_iterations:\n",
    "            self._stop()\n",
    "        else:\n",
    "            self._classify()\n",
    "            self._iteration += 1\n",
    "            self._iterate()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-382fbbaa360e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-4709130534b0>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, k, data, metric, normalize, max_iterations, seed)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-4709130534b0>\u001b[0m in \u001b[0;36m_iterate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-4709130534b0>\u001b[0m in \u001b[0;36m_iterate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-4709130534b0>\u001b[0m in \u001b[0;36m_classify\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcentroid_number\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 \u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_centroid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcentroid_number\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iteration\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mclosest_centroid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "model = KMeans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper = np.zeros(len(words[0].vector))\n",
    "lower = np.zeros(len(words[0].vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = words\n",
    "for d in data:\n",
    "    for i, x in enumerate(d.vector):\n",
    "        upper[i] = max(upper[i], x)\n",
    "        lower[i] = min(lower[i], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9422151 , 0.66847639, 0.6235339 , 0.50318015, 0.96120045,\n",
       "       0.45423418, 0.27690307, 0.66573002, 0.65241152, 0.51459606,\n",
       "       0.62995308, 0.76718602, 1.17113041, 0.5663309 , 1.17364014,\n",
       "       0.72471281, 0.85345423, 0.42913855, 0.64279426, 0.70656969,\n",
       "       0.66798549, 0.99611443, 0.52441065, 0.60746996, 0.6300324 ,\n",
       "       0.39739337, 0.54350117, 0.74914971, 0.62450148, 0.53624136,\n",
       "       0.97947521, 0.89714546, 1.03220124, 1.05269592, 0.79347277,\n",
       "       0.90272685, 0.75753707, 0.55162231, 0.57136249, 0.85180647,\n",
       "       1.02086072, 0.59752888, 0.71284922, 0.92541565, 0.45880458,\n",
       "       0.71743346, 0.63248002, 0.39146469, 0.5912805 , 0.62949498,\n",
       "       0.80115612, 0.45628878, 0.67111345, 0.82994368, 0.45044826,\n",
       "       0.68790664, 0.65303657, 0.66482551, 0.83947192, 0.43640757,\n",
       "       0.4992028 , 0.74253032, 0.63863375, 0.619351  , 0.76489725,\n",
       "       0.7781343 , 0.81104189, 0.6528093 , 0.3316934 , 0.76986848,\n",
       "       0.45524179, 0.77200181, 0.63765713, 0.79015257, 0.77833627,\n",
       "       0.72502265, 0.48155206, 0.69914165, 0.67753424, 0.7827778 ,\n",
       "       0.6611681 , 0.71834593, 0.69786533, 0.58556552, 0.14345423,\n",
       "       0.62024831, 0.77886164, 0.53909579, 0.83629134, 0.83093921,\n",
       "       0.47111707, 0.79031458, 0.53770348, 0.57443854, 0.82845891,\n",
       "       0.59423701, 0.10649193, 0.64775018, 0.79570703, 0.49020493,\n",
       "       0.5849993 , 0.63701556, 1.51697368, 0.66522942, 0.50263233,\n",
       "       0.45526789, 0.64480612, 1.34790829, 0.47514459, 0.65062749,\n",
       "       0.59324526, 0.58356338, 0.8325637 , 0.65016673, 0.60963972,\n",
       "       0.59871021, 0.63698291, 0.85947362, 0.50069612, 0.59746555,\n",
       "       0.58033741, 0.81485217, 0.69612388, 0.99216809, 0.95094285,\n",
       "       0.82895872, 0.6258439 , 0.69489281, 0.81726142, 0.7281649 ,\n",
       "       0.60967657, 0.6811024 , 0.5608291 , 0.95888204, 0.7510251 ,\n",
       "       0.45282564, 0.67146017, 0.90059675, 0.76221437, 0.6255451 ,\n",
       "       0.73189609, 0.43666438, 0.38174867, 0.79162798, 0.73334738,\n",
       "       0.89633651, 0.79160113, 0.85535511, 1.25556486, 0.62036747,\n",
       "       0.60437675, 0.4766656 , 0.87723691, 0.93155374, 0.70285808,\n",
       "       0.3646064 , 0.75434034, 0.71240983, 0.83762409, 0.5416159 ,\n",
       "       0.59195195, 0.64808691, 0.5183425 , 0.73012652, 0.87036108,\n",
       "       0.72128004, 0.41139608, 0.45410463, 0.58656049, 0.77409854,\n",
       "       0.68901015, 0.83144798, 0.68221051, 0.77155478, 0.50488928,\n",
       "       0.99298303, 0.69331296, 0.75128623, 0.89030348, 0.86610349,\n",
       "       0.59256431, 0.51577702, 0.42195888, 0.37939621, 0.98217809,\n",
       "       0.67904186, 0.54327486, 0.77749276, 0.80777733, 0.50843359,\n",
       "       0.74909928, 0.54996435, 0.7971145 , 1.07310638, 0.79151754,\n",
       "       0.76059462, 0.87161599, 0.46330501, 0.60880789, 0.5768355 ,\n",
       "       0.36217011, 0.51341358, 0.73057275, 0.63468135, 0.68285678,\n",
       "       0.74258627, 0.81181114, 0.58526842, 0.74039821, 0.66872875,\n",
       "       0.6794179 , 0.71137878, 0.70424424, 0.77575217, 0.56420237,\n",
       "       0.75686258, 0.78774367, 0.68368821, 0.75726599, 0.68206558,\n",
       "       0.54796813, 0.46913185, 0.61489498, 1.02576698, 0.1850268 ,\n",
       "       0.41625576, 0.97417062, 0.82622997, 0.77655315, 0.86693634,\n",
       "       0.70925977, 0.85016053, 0.91945536, 0.69473193, 0.83893328,\n",
       "       0.50743544, 0.62877776, 0.76122822, 0.54066122, 0.91685313,\n",
       "       0.65706566, 0.69366068, 0.72052872, 0.62551092, 0.5413942 ,\n",
       "       0.75954324, 0.66881699, 0.74079227, 0.92003315, 0.95757543,\n",
       "       0.66710769, 0.57260175, 0.79318107, 0.77798557, 0.56364759,\n",
       "       0.50914266, 0.82356493, 0.95396547, 0.58221093, 0.8717047 ,\n",
       "       0.72011562, 0.63470665, 0.64585001, 0.57392211, 0.47359971,\n",
       "       0.90172915, 0.52496075, 0.52978668, 0.48788319, 0.57438096,\n",
       "       0.69100513, 0.59016673, 0.92190968, 0.35378862, 0.5977814 ,\n",
       "       0.50703577, 0.76613208, 0.55690914, 0.36465476, 0.47137998,\n",
       "       0.82879671, 0.56462308, 0.7594875 , 0.95881807, 0.69966738,\n",
       "       0.57748898, 0.40248172, 0.524822  , 0.53836749, 0.55759958,\n",
       "       0.67776888, 0.77744169, 0.69890762, 0.81987572, 0.7216354 ,\n",
       "       0.5521634 , 0.69809724, 0.50131486, 0.60382697, 0.69749449])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids[0][0] #= \\\n",
    "#                     lower + np.random.random() * (upper - lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.99684, -0.91587, -1.0514 , -1.4107 , -0.88439, -1.6586 ,\n",
       "       -2.8027 , -0.95706, -1.0216 , -2.0161 , -1.3544 , -0.71916,\n",
       "       -0.78765, -1.306  , -0.85387, -0.95628, -0.99129, -1.2773 ,\n",
       "       -0.97502, -0.74652, -0.88368, -1.1614 , -0.68309, -0.79758,\n",
       "       -0.9627 , -1.0844 , -1.0948 , -1.1589 , -0.8113 , -0.76359,\n",
       "       -1.6845 , -0.91243, -0.84475, -0.89747, -0.4943 , -0.86348,\n",
       "       -1.084  , -0.85391, -0.93993, -0.74393, -0.55972, -0.89634,\n",
       "       -1.1886 , -1.0417 , -0.74994, -0.82764, -0.89737, -1.0151 ,\n",
       "       -1.038  , -1.1633 , -0.84163, -0.93281, -0.81178, -0.60436,\n",
       "       -1.4898 , -1.1582 , -1.1715 , -1.0008 , -0.5402 , -1.1432 ,\n",
       "       -0.98529, -1.1117 , -1.0757 , -0.7376 , -1.3685 , -0.75747,\n",
       "       -0.84723, -0.87765, -1.2229 , -0.79086, -1.3877 , -1.0092 ,\n",
       "       -0.83267, -0.72224, -0.59768, -0.81945, -0.92068, -0.82162,\n",
       "       -0.99162, -0.94463, -0.86352, -1.4489 , -0.75855, -1.5452 ,\n",
       "       -1.3396 , -1.2483 , -0.97945, -1.5953 , -1.011  , -1.2461 ,\n",
       "       -1.2257 , -1.1625 , -1.1626 , -1.1008 , -0.95518, -1.2982 ,\n",
       "       -2.4825 , -1.2253 , -0.849  , -1.3536 , -1.0488 , -1.1533 ,\n",
       "       -0.87848, -1.0116 , -1.3063 , -0.92195, -0.73963, -1.2438 ,\n",
       "       -0.81636, -0.82454, -1.193  , -1.1568 , -1.0567 , -0.98007,\n",
       "       -0.9885 , -0.97494, -0.69393, -0.70838, -0.87334, -0.97566,\n",
       "       -0.74901, -1.1262 , -0.96819, -1.0594 , -1.0716 , -0.82812,\n",
       "       -0.88379, -0.74833, -0.91739, -0.67086, -1.1321 , -0.798  ,\n",
       "       -0.98757, -0.80482, -0.90899, -0.88385, -0.71565, -1.0193 ,\n",
       "       -0.75369, -0.79681, -1.1792 , -0.8314 , -1.564  , -0.9278 ,\n",
       "       -0.71959, -1.1444 , -0.71172, -0.69114, -0.81473, -1.3403 ,\n",
       "       -1.0159 , -0.91102, -0.92083, -0.90659, -1.0076 , -1.1372 ,\n",
       "       -1.1312 , -0.88716, -0.97427, -1.0982 , -1.2221 , -0.93301,\n",
       "       -0.86914, -0.84569, -0.9837 , -1.4909 , -1.4789 , -0.93089,\n",
       "       -0.7015 , -0.88056, -0.77024, -0.80533, -0.96787, -0.58455,\n",
       "       -0.85994, -0.78392, -0.62797, -1.1307 , -0.99599, -1.0411 ,\n",
       "       -0.73647, -0.88076, -0.95817, -0.89251, -0.8938 , -0.88585,\n",
       "       -1.1962 , -0.92342, -0.74795, -1.1933 , -0.91546, -0.93474,\n",
       "       -0.96861, -1.0795 , -0.97364, -1.1307 , -0.97609, -0.97853,\n",
       "       -0.69605, -0.91287, -1.1482 , -1.0436 , -0.90827, -1.0784 ,\n",
       "       -0.77245, -1.0365 , -1.0948 , -1.1297 , -0.80641, -0.98868,\n",
       "       -0.87361, -1.0705 , -1.337  , -1.1653 , -1.2039 , -1.0141 ,\n",
       "       -1.2458 , -0.94577, -1.1628 , -1.0464 , -0.97716, -1.0026 ,\n",
       "       -1.1883 , -0.82496, -3.3685 , -1.3663 , -1.1115 , -0.85797,\n",
       "       -0.88826, -0.88216, -0.94121, -0.64513, -0.73379, -0.7781 ,\n",
       "       -0.78637, -1.1676 , -0.69501, -0.71333, -1.0983 , -0.68578,\n",
       "       -1.0725 , -0.77263, -1.0088 , -0.83368, -0.7965 , -1.0616 ,\n",
       "       -0.8616 , -0.91225, -1.0756 , -0.55194, -0.94513, -0.97006,\n",
       "       -1.0195 , -0.80576, -0.84048, -1.1078 , -1.0822 , -1.0624 ,\n",
       "       -0.82553, -0.74165, -0.8332 , -1.2322 , -0.72877, -1.1183 ,\n",
       "       -0.72136, -0.95746, -1.5004 , -1.0999 , -0.91913, -0.78202,\n",
       "       -0.8868 , -0.68878, -1.1718 , -1.2295 , -0.91957, -0.9863 ,\n",
       "       -0.96703, -1.5811 , -1.0325 , -1.0889 , -1.194  , -0.87194,\n",
       "       -0.95356, -0.77222, -0.82563, -1.0934 , -1.2329 , -1.1039 ,\n",
       "       -1.1125 , -0.93533, -0.88846, -0.98153, -1.1604 , -0.87948,\n",
       "       -0.82882, -1.0541 , -0.84602, -1.0109 , -0.84361, -0.89242])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(-1,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08111"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47727"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[1].vector[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower[0] = min(lower[0], words[1].vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08111"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower[i] = min(lower[i], words[j].vector[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'min(iterable, *[, default=obj, key=func]) -> value\\nmin(arg1, arg2, *args, *[, key=func]) -> value\\n\\nWith a single iterable argument, return its smallest item. The\\ndefault keyword-only argument specifies an object to return if\\nthe provided iterable is empty.\\nWith two or more arguments, return the smallest argument.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.08111  -0.50285  -0.055975  0.45965  -0.30271 ] \n",
      " [0.08111 0.      0.      0.45965 0.     ] \n",
      " [ 0.       -0.50285  -0.055975  0.       -0.30271 ] \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "1 [ 0.47727 -0.91587 -0.2977  -0.22489  0.55337] \n",
      " [0.47727 0.      0.      0.45965 0.55337] \n",
      " [ 0.      -0.91587 -0.2977  -0.22489 -0.30271] \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "2 [-0.33575  0.38897 -0.41929 -0.33219  0.5317 ] \n",
      " [0.47727 0.38897 0.      0.45965 0.55337] \n",
      " [-0.33575 -0.91587 -0.41929 -0.33219 -0.30271] \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "3 [ 0.2111   0.21763 -0.52638 -0.42277  0.84672] \n",
      " [0.47727 0.38897 0.      0.45965 0.84672] \n",
      " [-0.33575 -0.91587 -0.52638 -0.42277 -0.30271] \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "4 [ 0.08111  -0.50285  -0.055975  0.45965  -0.30271 ] \n",
      " [0.47727 0.38897 0.      0.45965 0.84672] \n",
      " [-0.33575 -0.91587 -0.52638 -0.42277 -0.30271] \n",
      " \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for j in range(5):\n",
    "    for i in range(5):\n",
    "        upper[i] = max([upper[i], words[j].vector[i]])\n",
    "        lower[i] = min([lower[i], words[j].vector[i]])\n",
    "    print(j, words[j].vector[0:5],'\\n', upper[0:5],'\\n', lower[0:5],'\\n', '\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.12452"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([0,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "w[1] = max(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -0.33575\n",
      "1 0.38897\n",
      "2 -0.41929\n",
      "3 -0.33219\n",
      "4 0.5317\n",
      "5 -0.25839\n",
      "6 -2.3869\n",
      "7 -0.43443\n",
      "8 -0.3976\n",
      "9 -0.99356\n",
      "10 0.47093\n",
      "11 -0.16265\n",
      "12 -0.13474\n",
      "13 -1.306\n",
      "14 0.34694\n",
      "15 0.1215\n",
      "16 -0.15811\n",
      "17 -0.011231\n",
      "18 -0.4656\n",
      "19 -0.18031\n",
      "20 0.026682\n",
      "21 -0.028445\n",
      "22 -0.44228\n",
      "23 0.20955\n",
      "24 0.044307\n",
      "25 0.27514\n",
      "26 -0.2314\n",
      "27 -0.10864\n",
      "28 -0.0087113\n",
      "29 0.20522\n",
      "30 0.36109\n",
      "31 -0.35431\n",
      "32 0.25217\n",
      "33 0.26608\n",
      "34 0.11942\n",
      "35 -0.21606\n",
      "36 0.073164\n",
      "37 0.25023\n",
      "38 0.24612\n",
      "39 0.20797\n",
      "40 -0.18702\n",
      "41 -0.038054\n",
      "42 0.23604\n",
      "43 0.42484\n",
      "44 0.10187\n",
      "45 0.058443\n",
      "46 -0.60782\n",
      "47 -0.52279\n",
      "48 -0.026276\n",
      "49 -0.14402\n",
      "50 0.22169\n",
      "51 -0.1585\n",
      "52 -0.81178\n",
      "53 0.082893\n",
      "54 -0.022136\n",
      "55 -0.12966\n",
      "56 0.17201\n",
      "57 0.62484\n",
      "58 -0.023122\n",
      "59 -0.15704\n",
      "60 -0.41946\n",
      "61 -0.49499\n",
      "62 0.056224\n",
      "63 -0.081352\n",
      "64 0.35428\n",
      "65 0.15145\n",
      "66 -0.26535\n",
      "67 0.10071\n",
      "68 -1.0047\n",
      "69 0.34271\n",
      "70 -0.003079\n",
      "71 0.35994\n",
      "72 0.4007\n",
      "73 0.1518\n",
      "74 0.11983\n",
      "75 -0.30275\n",
      "76 0.13739\n",
      "77 -0.36725\n",
      "78 0.3665\n",
      "79 0.31037\n",
      "80 0.513\n",
      "81 0.20102\n",
      "82 -0.34841\n",
      "83 0.28565\n",
      "84 -0.48071\n",
      "85 0.21667\n",
      "86 -0.37125\n",
      "87 0.60281\n",
      "88 0.099829\n",
      "89 -0.47562\n",
      "90 -0.094234\n",
      "91 -0.19625\n",
      "92 -0.12658\n",
      "93 0.025421\n",
      "94 -0.10805\n",
      "95 -0.95298\n",
      "96 -2.1365\n",
      "97 -0.25989\n",
      "98 0.2901\n",
      "99 -0.14846\n",
      "100 -0.06318\n",
      "101 -0.16572\n",
      "102 0.0073842\n",
      "103 -0.30222\n",
      "104 -0.28538\n",
      "105 0.47556\n",
      "106 0.041736\n",
      "107 -0.15516\n",
      "108 0.39398\n",
      "109 -0.60727\n",
      "110 0.7889\n",
      "111 -0.092844\n",
      "112 0.32725\n",
      "113 -0.19599\n",
      "114 -0.21146\n",
      "115 0.023927\n",
      "116 -0.17896\n",
      "117 -0.065021\n",
      "118 0.52246\n",
      "119 -0.38243\n",
      "120 -0.4467\n",
      "121 0.07913\n",
      "122 0.82286\n",
      "123 0.55868\n",
      "124 0.030237\n",
      "125 -0.3001\n",
      "126 0.48222\n",
      "127 0.54899\n",
      "128 -0.3224\n",
      "129 -0.67086\n",
      "130 -0.61622\n",
      "131 0.066708\n",
      "132 0.30572\n",
      "133 0.01517\n",
      "134 -0.52623\n",
      "135 0.15352\n",
      "136 -0.66473\n",
      "137 -0.2077\n",
      "138 0.25136\n",
      "139 0.36206\n",
      "140 -0.22424\n",
      "141 0.00085694\n",
      "142 0.046224\n",
      "143 -0.015066\n",
      "144 -0.32618\n",
      "145 -0.097696\n",
      "146 0.021966\n",
      "147 0.27861\n",
      "148 0.1584\n",
      "149 -0.2021\n",
      "150 0.072365\n",
      "151 -0.1957\n",
      "152 -0.26862\n",
      "153 0.13854\n",
      "154 0.041905\n",
      "155 -0.063822\n",
      "156 -0.32484\n",
      "157 0.055546\n",
      "158 0.28501\n",
      "159 0.67519\n",
      "160 0.30155\n",
      "161 -0.50474\n",
      "162 -0.67976\n",
      "163 0.51983\n",
      "164 0.065695\n",
      "165 0.025286\n",
      "166 -0.096823\n",
      "167 -0.052386\n",
      "168 -0.057766\n",
      "169 0.02108\n",
      "170 -0.24691\n",
      "171 -0.80533\n",
      "172 -0.18712\n",
      "173 0.47986\n",
      "174 -0.45478\n",
      "175 -0.076232\n",
      "176 0.63681\n",
      "177 -0.46249\n",
      "178 0.23123\n",
      "179 0.079812\n",
      "180 -0.61783\n",
      "181 -0.054644\n",
      "182 -0.0015799\n",
      "183 0.1465\n",
      "184 0.053362\n",
      "185 -0.04977\n",
      "186 -0.63187\n",
      "187 -0.11563\n",
      "188 0.38775\n",
      "189 0.10124\n",
      "190 -0.0032881\n",
      "191 0.17987\n",
      "192 -0.06248\n",
      "193 -0.27772\n",
      "194 -0.48288\n",
      "195 -0.37275\n",
      "196 0.61105\n",
      "197 -0.3227\n",
      "198 0.69697\n",
      "199 0.088196\n",
      "200 0.44661\n",
      "201 -0.0065324\n",
      "202 -0.10571\n",
      "203 0.946\n",
      "204 -0.19661\n",
      "205 -0.39961\n",
      "206 0.29346\n",
      "207 0.1364\n",
      "208 0.42281\n",
      "209 -0.45546\n",
      "210 0.54213\n",
      "211 -0.19004\n",
      "212 0.55959\n",
      "213 -0.39935\n",
      "214 0.12659\n",
      "215 -0.29526\n",
      "216 -0.11524\n",
      "217 0.10132\n",
      "218 -0.16572\n",
      "219 0.38628\n",
      "220 -0.25172\n",
      "221 0.30096\n",
      "222 -0.22338\n",
      "223 -0.093883\n",
      "224 -3.1209\n",
      "225 0.07981\n",
      "226 -1.1115\n",
      "227 0.16649\n",
      "228 -0.23107\n",
      "229 -0.12312\n",
      "230 0.20972\n",
      "231 -0.007045\n",
      "232 -0.73021\n",
      "233 -0.47405\n",
      "234 -0.28147\n",
      "235 0.0010118\n",
      "236 0.66102\n",
      "237 -0.011403\n",
      "238 0.031912\n",
      "239 0.50367\n",
      "240 0.51864\n",
      "241 -0.060027\n",
      "242 -0.15285\n",
      "243 0.73159\n",
      "244 -0.5533\n",
      "245 -0.16912\n",
      "246 -0.063391\n",
      "247 0.13858\n",
      "248 0.28878\n",
      "249 0.15076\n",
      "250 -0.22552\n",
      "251 0.28992\n",
      "252 0.54796\n",
      "253 0.1551\n",
      "254 0.51603\n",
      "255 -0.19686\n",
      "256 -0.64146\n",
      "257 0.50649\n",
      "258 0.70221\n",
      "259 -0.21417\n",
      "260 0.35252\n",
      "261 -0.29347\n",
      "262 -0.19962\n",
      "263 -0.055284\n",
      "264 -0.10027\n",
      "265 0.3333\n",
      "266 0.49459\n",
      "267 0.17876\n",
      "268 -0.041699\n",
      "269 0.46649\n",
      "270 -0.3172\n",
      "271 -0.32616\n",
      "272 0.12663\n",
      "273 -0.4367\n",
      "274 -0.54299\n",
      "275 -0.10077\n",
      "276 -0.26449\n",
      "277 0.10524\n",
      "278 -0.325\n",
      "279 -0.28024\n",
      "280 0.49458\n",
      "281 -0.0028948\n",
      "282 -0.86985\n",
      "283 -0.089116\n",
      "284 -0.23145\n",
      "285 -0.40411\n",
      "286 -0.02368\n",
      "287 0.24752\n",
      "288 0.32651\n",
      "289 -0.053385\n",
      "290 -0.11501\n",
      "291 -0.55804\n",
      "292 0.48427\n",
      "293 0.25167\n",
      "294 -0.068426\n",
      "295 0.34227\n",
      "296 0.2684\n",
      "297 -0.14929\n",
      "298 -0.23516\n",
      "299 0.039194\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(words[2].vector): print(i,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.8577e-01, -3.7071e-01, -1.2452e-01, -6.0234e-01,  7.0299e-01,\n",
       "       -1.4603e+00, -5.2778e-01, -3.5435e-02, -4.3165e-01, -1.0401e+00,\n",
       "        2.6789e-01, -2.9573e-01,  8.7415e-01,  2.4446e-01,  3.6380e-01,\n",
       "       -4.8924e-01, -3.0546e-01, -1.1816e+00,  5.2453e-01,  4.4108e-02,\n",
       "        2.6787e-01, -1.5690e-02,  1.3511e-01,  3.5650e-01, -2.2939e-01,\n",
       "        6.1426e-02, -2.4105e-01, -1.1017e-01, -5.1229e-01, -4.0380e-02,\n",
       "        8.3256e-01, -2.5489e-01,  2.3119e-01,  4.6005e-02,  2.5584e-01,\n",
       "       -1.7051e-01, -7.3765e-01,  5.6647e-01, -2.5144e-01,  6.0860e-01,\n",
       "        3.7638e-01, -1.5358e-01,  2.3254e-01,  1.9730e-01, -7.8956e-03,\n",
       "        1.4744e-01, -5.6575e-02, -6.7243e-03,  3.1051e-01, -6.7962e-01,\n",
       "       -1.6831e-01,  2.4753e-01, -2.5611e-01,  6.4161e-01, -7.7726e-01,\n",
       "       -3.1699e-01,  6.5896e-02,  4.7737e-01,  1.3933e-01,  3.9412e-01,\n",
       "        2.4505e-02,  6.0498e-01, -4.8965e-01, -7.2412e-02, -5.4783e-01,\n",
       "       -7.5747e-01, -8.4723e-01,  6.1058e-02, -1.8614e-01, -4.9159e-01,\n",
       "       -4.6957e-01, -4.9365e-01, -1.9644e-01,  1.4703e-01,  2.5994e-01,\n",
       "        4.0746e-01,  3.8054e-01,  2.0153e-01,  1.6043e-01, -2.8710e-01,\n",
       "        3.8908e-01,  3.6102e-01, -2.5516e-01,  2.4678e-01, -3.4257e-01,\n",
       "       -5.2115e-01, -4.9334e-01,  2.2535e-02, -3.2240e-01,  3.7576e-01,\n",
       "       -2.6138e-01, -2.2281e-01, -7.1527e-01, -2.6512e-01, -1.1340e-01,\n",
       "       -4.6857e-04, -2.5335e-01, -3.9165e-01,  1.7922e-01, -9.8354e-02,\n",
       "       -1.8176e-01,  1.6904e-01,  1.5080e+00,  1.3038e-01, -1.4664e-02,\n",
       "        2.7340e-01, -2.1647e-01,  1.1091e-01, -1.6183e-01, -2.8939e-01,\n",
       "        9.1442e-02,  1.6877e-01,  4.5932e-01,  6.0256e-01, -4.4366e-01,\n",
       "       -9.5289e-02,  2.0498e-01, -2.4375e-01, -2.2084e-01,  5.0211e-01,\n",
       "        1.6298e-01, -3.5626e-02, -4.2783e-01, -1.8891e-01, -1.7787e-01,\n",
       "        5.8880e-01, -3.2753e-01, -6.1436e-02, -4.9818e-01, -8.8242e-02,\n",
       "        2.8519e-02, -3.3089e-02,  3.3099e-01, -4.1230e-02,  1.5830e-01,\n",
       "       -1.8678e-02,  5.1118e-01, -3.9184e-01,  4.7844e-01,  3.7132e-01,\n",
       "        4.5753e-01, -7.5318e-02, -8.6503e-01,  5.6242e-03,  9.9739e-01,\n",
       "       -8.7824e-01,  2.3515e-01,  3.0602e-01,  1.1218e+00,  4.0997e-01,\n",
       "       -6.3033e-01,  2.2725e-01,  1.0866e-01, -9.1704e-02,  4.4766e-01,\n",
       "       -8.2066e-02,  2.0854e-01,  1.6936e-02, -3.6940e-02, -8.4784e-01,\n",
       "       -1.7232e-01, -3.1689e-01, -9.0258e-02,  7.8596e-02,  9.0627e-01,\n",
       "        1.3765e-03, -8.1721e-01, -4.1188e-01,  6.0709e-01,  9.2194e-01,\n",
       "       -3.5721e-01,  5.0955e-01, -1.3762e-01, -3.3212e-01,  2.7345e-02,\n",
       "        5.9417e-01,  4.9930e-01,  7.4573e-01, -4.3607e-01, -3.1641e-01,\n",
       "        4.8793e-02,  7.5142e-01, -4.5437e-01, -6.3253e-02, -4.7707e-01,\n",
       "        3.9859e-02, -1.2800e-01, -4.1585e-01,  3.8931e-01,  2.3148e-01,\n",
       "        1.5342e-01,  4.5592e-01, -5.6632e-01, -6.9222e-01, -1.9509e-01,\n",
       "        5.6731e-01,  3.1481e-01, -2.3260e-01, -2.7003e-01, -1.5079e-01,\n",
       "       -2.4694e-02, -2.5741e-01,  6.4546e-02, -1.5701e-01,  4.1378e-01,\n",
       "        3.1802e-01,  1.8095e-01, -1.1297e+00, -1.1413e-01,  2.3702e-02,\n",
       "        1.0995e-01, -6.4466e-02,  2.2153e-01, -3.0573e-01, -3.4883e-01,\n",
       "       -3.7628e-01, -1.2628e-01, -4.6851e-01, -2.6135e-01, -1.2787e-01,\n",
       "        1.7719e-01,  3.3188e-01,  2.3055e-01, -5.8209e-01, -8.8992e-01,\n",
       "        9.2342e-02,  9.6481e-01,  3.3901e-01,  2.2622e-01,  6.7987e-01,\n",
       "       -2.3194e-02, -8.3808e-02,  4.1061e-01, -3.7866e-01, -2.2950e-01,\n",
       "       -2.0297e-02,  6.4927e-02, -1.2502e-01, -4.4204e-01,  4.8715e-01,\n",
       "       -9.5559e-02,  6.1615e-01, -3.7470e-02,  7.7049e-01, -4.6711e-01,\n",
       "        4.7659e-01,  1.6234e-01, -2.1833e-01, -5.7905e-03,  8.5272e-01,\n",
       "       -7.8686e-02,  3.1657e-01,  2.1129e-01,  1.4466e-02,  3.1992e-01,\n",
       "       -8.3385e-02, -2.3255e-01,  5.4719e-01, -2.1005e-01,  2.9976e-01,\n",
       "        8.2239e-02, -3.6287e-01, -2.5548e-01, -4.1357e-01, -1.9872e-01,\n",
       "        9.4535e-01, -1.4025e-01,  5.6538e-02,  1.1061e-01,  3.5359e-01,\n",
       "        2.9881e-01, -3.4140e-01, -5.4899e-01, -1.8242e-01,  2.0288e-01,\n",
       "       -4.9300e-01,  3.8156e-01, -4.0615e-01, -2.9483e-01,  5.2521e-02,\n",
       "        9.0250e-01, -2.1851e-01, -2.2705e-01,  6.9074e-01,  1.5603e-01,\n",
       "        2.0257e-02,  7.6925e-02, -4.2474e-01, -8.1828e-02, -5.3249e-01,\n",
       "       -6.0179e-01, -4.6614e-01,  3.3780e-01, -1.6593e-02,  3.2760e-01,\n",
       "       -9.3397e-02,  1.6020e-02, -5.4729e-03, -8.4361e-01,  8.7304e-02])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(words[0]['vector'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = '0.53533'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53533"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['animals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "]\n",
    "\n",
    "\n",
    "animal = open('animals').read().split('\\n')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for a in animals:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-255a6ca5673f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manimals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manimals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "animals = animals.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Computation\n",
    "\n",
    "> (2) Vary the value of k from 1 to 10 and compute the precision, recall, and F-score for each set of clusters. Plot k in the horizontal axis and precision, recall and F-score in the vertical axis in the same plot. (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize\n",
    "\n",
    "> (3) Now re-run the k-means clustering algorithm you implemented in part (1) but normalise each feature vector to unit L2 length before computing Euclidean distances. Vary the value of k from 1 to 10 and compute the precision, recall, and F-score for each set of clusters. Plot k in the horizontal axis and precision, recall and F-score in the vertical axis in the same plot. (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manhattan Distance\n",
    "\n",
    "> (4) Now re-run the k-means clustering algorithm you implemented in part (1) but this time use Manhattan distance over the unnormalised feature vectors. Vary the value of k from 1 to 10\n",
    "and compute the precision, recall, and F-score for each set of clusters. Plot k in the horizontal axis and precision, recall and F-score in the vertical axis in the same plot. (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Manhattan Distance\n",
    "\n",
    "> (5) Now re-run the k-means clustering algorithm you implemented in part (1) but this time use Manhattan distance with L2 normalised feature vectors. Vary the value of k from 1 to 10 and\n",
    "compute the precision, recall, and F-score for each set of clusters. Plot k in the horizontal axis and precision, recall and F-score in the vertical axis in the same plot. (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cosine Similarity\n",
    "\n",
    "> (6) Now re-run the k-means clustering algorithm you implemented in part (1) but this time use cosine similarity as the distance (similarity) measure.Vary the value of k from 1 to 10 andcompute the precision, recall, and F-score for each set of clusters. Plot k in the horizontal axis and precision, recall and F-score in the vertical axis in the same plot. (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare and Discuss\n",
    "\n",
    "> (7) Comparing the different clusterings you obtained in (2)-(6) discuss what is the best setting for k-means clustering for this dataset. (20 marks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
