{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP 527: Implementing the k-means clustering algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In the assignment, you are required to cluster words belonging to four categories: animals, countries, fruits and veggies. The words are arranged into four different files. The first entry in each line is a word followed by 300 features (word embedding) describing the meaning of that word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    " \n",
    "> (1) Implement the k-means clustering algorithm with Euclidean distance to cluster the instances into k clusters. (30 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import scipy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word():\n",
    "    \"\"\"Object class for a categorized word with data vector.\"\"\"\n",
    "    \n",
    "    def __init__(self, name, vector, category):\n",
    "        self.name = name\n",
    "        self.vector = vector\n",
    "        self.category = category\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'word: {self.name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(list_of_filenames):\n",
    "    \"\"\"Read in data.\"\"\"\n",
    "\n",
    "    collection = []\n",
    "\n",
    "    for filename in list_of_filenames:\n",
    "        data = open(filename).read().split('\\n')[:-1]\n",
    "\n",
    "        for word_data in data:\n",
    "            split = word_data.split(' ')\n",
    "            name = split[0]\n",
    "            raw_list = split[1:]\n",
    "\n",
    "            floats = []\n",
    "            for x_string in raw_list:\n",
    "                floats.append(float(x_string))\n",
    "\n",
    "            vector = np.array(floats)\n",
    "\n",
    "            collection.append( Word(name, vector, filename))\n",
    "\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329\n"
     ]
    }
   ],
   "source": [
    "categories = ['animals', 'countries', 'fruits', 'veggies']\n",
    "words = read_data(categories)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "animals 50\n",
      "countries 161\n",
      "fruits 58\n",
      "veggies 60\n"
     ]
    }
   ],
   "source": [
    "category = {}\n",
    "for c in categories:\n",
    "    category[c] = []\n",
    "    for w in words:\n",
    "        if w.category == c:\n",
    "            category[c].append(w)\n",
    "    print(c, len(category[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words:\n",
    "    if w.vector.shape != words[0].vector.shape:\n",
    "        print('ERROR', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.015926, -0.079864])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0].vector[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(data):\n",
    "    \"\"\"Return two-dimensional vectors.\"\"\"\n",
    "\n",
    "    flat = []\n",
    "\n",
    "    for d in data:\n",
    "        two_dim = d.vector[0:2]\n",
    "        flat.append(Word(d.name, two_dim, d.category))\n",
    "\n",
    "    return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = flatten(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.015926, -0.079864])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat[0].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(u, v):\n",
    "    \"\"\"Return Euclidean distance between two np.array vectors.\"\"\"\n",
    "\n",
    "    return np.sqrt( (u - v).dot( u - v ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(u, v):\n",
    "    \"\"\"Return Manhattan distance between two np.array vectors.\"\"\"\n",
    "\n",
    "    w = u - v\n",
    "    distance = 0\n",
    "    for x in w:\n",
    "        distance += abs(x)\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(u, v):\n",
    "    \"\"\"Return Cosine similarity of two np.array vectors.\"\"\"\n",
    "    \n",
    "    return u.dot(v)/( np.sqrt(u.dot(u)) * np.sqrt(v.dot(v)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    \"\"\"Return normalized vectors (ie. parallel vector with unit magnitude).\"\"\"\n",
    "    \n",
    "    normalized_data = []\n",
    "    \n",
    "    for d in data:\n",
    "        normalized_vector = d.vector / np.sqrt( d.vector.dot(d.vector) )\n",
    "        normalized_data.append(Word(d.name, normalized_vector, d.category))\n",
    "        \n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = euclidean_distance, manhattan_distance, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142135623730951\n",
      "2\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for metric in metrics:\n",
    "    print(metric(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "class KMeans():\n",
    "    \n",
    "    def __init__(\n",
    "                self, \n",
    "                k = 4, \n",
    "                data = words, \n",
    "                metric = euclidean_distance, \n",
    "                normalize = False, \n",
    "                max_iterations = 10**3, \n",
    "                seed = None,\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Initialize KMeans Model.\n",
    "        \n",
    "        Args:\n",
    "            k (int): number of clusters to divide data into.\n",
    "            data (list): list of dicts which must each include\n",
    "                the keys 'name' (string) and 'vector' (np.ndarray).\n",
    "            metric (function): to measure distance between points.\n",
    "            normalize (Boolean): whether or not to normalize vectors.\n",
    "            iterations (int): when to stop if no convergence.\n",
    "            seed (int): for reproducible (pseudo-)randomness.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.k = k\n",
    "        \n",
    "        if normalize:\n",
    "            self.data = normalize(data)\n",
    "        else:\n",
    "            self.data = data\n",
    "        \n",
    "        self.metric = metric\n",
    "        \n",
    "        self._upperbound, self._lowerbound = self._bounds()\n",
    "        \n",
    "        if seed:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        # we track centroid positions and cluster labels in nested dicts,\n",
    "        # of the form dict_name[centroid_number][iteration_number]\n",
    "        self._centroid = {}\n",
    "        for centroid_number in range(k):\n",
    "            self._centroid[centroid_number] = {}\n",
    "        \n",
    "        self._cluster = {}\n",
    "        for centroid_number in range(k):\n",
    "            self._cluster[centroid_number] = {}\n",
    "\n",
    "        # we record cluster labels explicitly as well\n",
    "        self._label = {}\n",
    "        for datum in data:\n",
    "            self._label[datum.name] = {}\n",
    "        \n",
    "        self.max_iterations = max_iterations\n",
    "        for i in range(self.max_iterations):\n",
    "            self._iteration = i\n",
    "            self._iterate()\n",
    "        \n",
    "        \n",
    "    def _bounds(self):\n",
    "        \"\"\"Find upper and lower bounds of data space.\"\"\"\n",
    "        \n",
    "        upper = np.zeros(len(words[0].vector))\n",
    "        lower = np.zeros(len(words[0].vector))\n",
    "        \n",
    "        for d in self.data:\n",
    "            for i, x in enumerate(d.vector):\n",
    "                upper[i] = max(upper[i], x)\n",
    "                lower[i] = min(lower[i], x)\n",
    "        \n",
    "        return upper, lower\n",
    "    \n",
    "    \n",
    "    def _start(self):\n",
    "        \"\"\"Generate starting positions for k centroids.\"\"\"\n",
    "        \n",
    "        for centroid_number in range(self.k):\n",
    "            self._centroid[centroid_number][0] = self._lowerbound \\\n",
    "                + np.random.random() * (self._upperbound - self._lowerbound)\n",
    "        print('centroids successfully positioned')\n",
    "    \n",
    "    \n",
    "    def _classify(self):\n",
    "        \"\"\"Assign each data point to cluster of nearest centroid.\"\"\"\n",
    "        \n",
    "        for centroid_number in range(self.k):\n",
    "            self._cluster[centroid_number][self._iteration] = []\n",
    "        \n",
    "        for d in self.data:\n",
    "            distances = []\n",
    "            \n",
    "            for centroid_number in range(self.k):\n",
    "                \n",
    "                distances.append(self.metric(d.vector, self._centroid[centroid_number][self._iteration]))\n",
    "            \n",
    "            closest_centroid = np.argmin(distances)\n",
    "            \n",
    "            self._cluster[closest_centroid][self._iteration].append(d)\n",
    "            self._label[d.name][self._iteration] = closest_centroid\n",
    "        \n",
    "        print(f'classification successful for iteration {self._iteration}')\n",
    "\n",
    "            \n",
    "    def _reposition(self):\n",
    "        \"\"\"Move centroids to mean of each cluster.\"\"\"\n",
    "        \n",
    "        for centroid_number in range(self.k):\n",
    "            \n",
    "            clustered = self._cluster[centroid_number][self._iteration - 1]\n",
    "            \n",
    "            if len(clustered) > 0:\n",
    "                vector_sum = np.zeros(len(clustered[0].vector))\n",
    "                \n",
    "                for datum in clustered:\n",
    "                    vector_sum += datum.vector\n",
    "\n",
    "                cluster_mean = vector_sum / len(clustered)\n",
    "\n",
    "                self._centroid[centroid_number][self._iteration] = cluster_mean\n",
    "\n",
    "            else:\n",
    "                # nothing assigned to this cluster\n",
    "                self._centroid[centroid_number][self._iteration] = self._centroid[centroid_number][self._iteration -1] \n",
    "        \n",
    "        print(f'repositioning successful for iteration {self._iteration}')\n",
    "            \n",
    "            \n",
    "    def _stop():\n",
    "        \"\"\"Stop iterating and return results.\"\"\"\n",
    "        \n",
    "        return 'done'\n",
    "    \n",
    "    def _iterate(self):\n",
    "        \"\"\"Position centroids and classify data by nearest centroid.\"\"\"\n",
    "        \n",
    "        if self._iteration == 0:\n",
    "            self._start()\n",
    "        else:\n",
    "            self._reposition()\n",
    "        \n",
    "        if self._iteration == self.max_iterations:\n",
    "            self._stop()\n",
    "        else:\n",
    "            self._classify()\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[word: elephant,\n",
       " word: leopard,\n",
       " word: dog,\n",
       " word: cat,\n",
       " word: aligator,\n",
       " word: ant,\n",
       " word: baboon,\n",
       " word: bear,\n",
       " word: bat,\n",
       " word: butterfly,\n",
       " word: camel,\n",
       " word: catfish,\n",
       " word: fish,\n",
       " word: cow,\n",
       " word: crow,\n",
       " word: boa,\n",
       " word: dolphin,\n",
       " word: donkey,\n",
       " word: eagle,\n",
       " word: falcon,\n",
       " word: fox,\n",
       " word: frog,\n",
       " word: gecko,\n",
       " word: giraffe,\n",
       " word: goat,\n",
       " word: gibbon,\n",
       " word: hampster,\n",
       " word: hawk,\n",
       " word: hare,\n",
       " word: horse,\n",
       " word: hummingbird,\n",
       " word: hippopotamus,\n",
       " word: iguana,\n",
       " word: jaguar,\n",
       " word: kangaroo,\n",
       " word: lion,\n",
       " word: leech,\n",
       " word: mouse,\n",
       " word: mosquito,\n",
       " word: owl,\n",
       " word: panda,\n",
       " word: penguin,\n",
       " word: parrot,\n",
       " word: peacock,\n",
       " word: rabbit,\n",
       " word: raven,\n",
       " word: shark,\n",
       " word: snake,\n",
       " word: spider,\n",
       " word: tiger,\n",
       " word: afghanistan,\n",
       " word: albania,\n",
       " word: algeria,\n",
       " word: andorra,\n",
       " word: angola,\n",
       " word: argentina,\n",
       " word: armenia,\n",
       " word: aruba,\n",
       " word: australia,\n",
       " word: austria,\n",
       " word: azerbaijan,\n",
       " word: bahrain,\n",
       " word: bangladesh,\n",
       " word: barbados,\n",
       " word: belarus,\n",
       " word: belgium,\n",
       " word: belize,\n",
       " word: benin,\n",
       " word: bhutan,\n",
       " word: bolivia,\n",
       " word: botswana,\n",
       " word: brazil,\n",
       " word: brunei,\n",
       " word: bulgaria,\n",
       " word: burma,\n",
       " word: burundi,\n",
       " word: cambodia,\n",
       " word: cameroon,\n",
       " word: canada,\n",
       " word: chad,\n",
       " word: chile,\n",
       " word: china,\n",
       " word: colombia,\n",
       " word: comoros,\n",
       " word: croatia,\n",
       " word: cuba,\n",
       " word: curacao,\n",
       " word: cyprus,\n",
       " word: czechia,\n",
       " word: denmark,\n",
       " word: djibouti,\n",
       " word: dominica,\n",
       " word: ecuador,\n",
       " word: egypt,\n",
       " word: eritrea,\n",
       " word: estonia,\n",
       " word: ethiopia,\n",
       " word: fiji,\n",
       " word: finland,\n",
       " word: france,\n",
       " word: gabon,\n",
       " word: georgia,\n",
       " word: germany,\n",
       " word: ghana,\n",
       " word: greece,\n",
       " word: grenada,\n",
       " word: guatemala,\n",
       " word: guinea,\n",
       " word: guinea-bissau,\n",
       " word: guyana,\n",
       " word: haiti,\n",
       " word: honduras,\n",
       " word: hungary,\n",
       " word: iceland,\n",
       " word: india,\n",
       " word: indonesia,\n",
       " word: iran,\n",
       " word: iraq,\n",
       " word: ireland,\n",
       " word: israel,\n",
       " word: italy,\n",
       " word: jamaica,\n",
       " word: japan,\n",
       " word: kazakhstan,\n",
       " word: kenya,\n",
       " word: kiribati,\n",
       " word: kosovo,\n",
       " word: kuwait,\n",
       " word: kyrgyzstan,\n",
       " word: laos,\n",
       " word: latvia,\n",
       " word: lebanon,\n",
       " word: lesotho,\n",
       " word: liberia,\n",
       " word: libya,\n",
       " word: liechtenstein,\n",
       " word: lithuania,\n",
       " word: luxembourg,\n",
       " word: macau,\n",
       " word: macedonia,\n",
       " word: madagascar,\n",
       " word: malawi,\n",
       " word: malaysia,\n",
       " word: maldives,\n",
       " word: mali,\n",
       " word: malta,\n",
       " word: mauritania,\n",
       " word: mauritius,\n",
       " word: mexico,\n",
       " word: micronesia,\n",
       " word: moldova,\n",
       " word: monaco,\n",
       " word: mongolia,\n",
       " word: montenegro,\n",
       " word: morocco,\n",
       " word: mozambique,\n",
       " word: namibia,\n",
       " word: nauru,\n",
       " word: nepal,\n",
       " word: netherlands,\n",
       " word: nicaragua,\n",
       " word: niger,\n",
       " word: nigeria,\n",
       " word: norway,\n",
       " word: oman,\n",
       " word: pakistan,\n",
       " word: palau,\n",
       " word: panama,\n",
       " word: paraguay,\n",
       " word: peru,\n",
       " word: philippines,\n",
       " word: poland,\n",
       " word: portugal,\n",
       " word: qatar,\n",
       " word: romania,\n",
       " word: russia,\n",
       " word: rwanda,\n",
       " word: samoa,\n",
       " word: senegal,\n",
       " word: serbia,\n",
       " word: seychelles,\n",
       " word: singapore,\n",
       " word: slovakia,\n",
       " word: somalia,\n",
       " word: spain,\n",
       " word: sudan,\n",
       " word: suriname,\n",
       " word: swaziland,\n",
       " word: sweden,\n",
       " word: switzerland,\n",
       " word: syria,\n",
       " word: taiwan,\n",
       " word: tajikistan,\n",
       " word: tanzania,\n",
       " word: thailand,\n",
       " word: togo,\n",
       " word: tonga,\n",
       " word: tunisia,\n",
       " word: turkey,\n",
       " word: turkmenistan,\n",
       " word: tuvalu,\n",
       " word: uganda,\n",
       " word: ukraine,\n",
       " word: uruguay,\n",
       " word: uzbekistan,\n",
       " word: vanuatu,\n",
       " word: venezuela,\n",
       " word: vietnam,\n",
       " word: yemen,\n",
       " word: zambia,\n",
       " word: zimbabwe,\n",
       " word: apple,\n",
       " word: apricot,\n",
       " word: avocado,\n",
       " word: banana,\n",
       " word: bilberry,\n",
       " word: blackberry,\n",
       " word: blackcurrant,\n",
       " word: blueberry,\n",
       " word: boysenberry,\n",
       " word: currant,\n",
       " word: cherry,\n",
       " word: cherimoya,\n",
       " word: cloudberry,\n",
       " word: coconut,\n",
       " word: cranberry,\n",
       " word: cucumber,\n",
       " word: damson,\n",
       " word: dragonfruit,\n",
       " word: durian,\n",
       " word: elderberry,\n",
       " word: feijoa,\n",
       " word: fig,\n",
       " word: gooseberry,\n",
       " word: grape,\n",
       " word: raisin,\n",
       " word: grapefruit,\n",
       " word: guava,\n",
       " word: honeyberry,\n",
       " word: huckleberry,\n",
       " word: jabuticaba,\n",
       " word: jackfruit,\n",
       " word: jambul,\n",
       " word: jujube,\n",
       " word: kiwano,\n",
       " word: kiwifruit,\n",
       " word: kumquat,\n",
       " word: lemon,\n",
       " word: lime,\n",
       " word: loquat,\n",
       " word: longan,\n",
       " word: lychee,\n",
       " word: mango,\n",
       " word: mangosteen,\n",
       " word: marionberry,\n",
       " word: melon,\n",
       " word: cantaloupe,\n",
       " word: honeydew,\n",
       " word: watermelon,\n",
       " word: mulberry,\n",
       " word: nectarine,\n",
       " word: nance,\n",
       " word: olive,\n",
       " word: orange,\n",
       " word: clementine,\n",
       " word: mandarine,\n",
       " word: tangerine,\n",
       " word: papaya,\n",
       " word: peach,\n",
       " word: aubergine,\n",
       " word: amaranth,\n",
       " word: asparagus,\n",
       " word: legumes,\n",
       " word: beans,\n",
       " word: chickpeas,\n",
       " word: lentils,\n",
       " word: peas,\n",
       " word: broccoli,\n",
       " word: cabbage,\n",
       " word: kohlrabi,\n",
       " word: cauliflower,\n",
       " word: celery,\n",
       " word: endive,\n",
       " word: fiddleheads,\n",
       " word: frisee,\n",
       " word: fennel,\n",
       " word: greens,\n",
       " word: kale,\n",
       " word: spinach,\n",
       " word: anise,\n",
       " word: basil,\n",
       " word: caraway,\n",
       " word: cilantro,\n",
       " word: coriander,\n",
       " word: chamomile,\n",
       " word: dill,\n",
       " word: lavender,\n",
       " word: marjoram,\n",
       " word: oregano,\n",
       " word: parsley,\n",
       " word: rosemary,\n",
       " word: sage,\n",
       " word: thyme,\n",
       " word: lettuce,\n",
       " word: arugula,\n",
       " word: mushrooms,\n",
       " word: nettles,\n",
       " word: okra,\n",
       " word: onions,\n",
       " word: chives,\n",
       " word: garlic,\n",
       " word: leek,\n",
       " word: onion,\n",
       " word: shallot,\n",
       " word: peppers,\n",
       " word: habanero,\n",
       " word: paprika,\n",
       " word: radicchio,\n",
       " word: rhubarb,\n",
       " word: turnip,\n",
       " word: radish,\n",
       " word: courgette,\n",
       " word: cucumber,\n",
       " word: delicata,\n",
       " word: pumpkin,\n",
       " word: potato,\n",
       " word: quandong,\n",
       " word: sunchokes,\n",
       " word: zucchini]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._cluster[2][999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper = np.zeros(len(words[0].vector))\n",
    "lower = np.zeros(len(words[0].vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = words\n",
    "for d in data:\n",
    "    for i, x in enumerate(d.vector):\n",
    "        upper[i] = max(upper[i], x)\n",
    "        lower[i] = min(lower[i], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'centroids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-bac3d91f80fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcentroids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#= \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#                     lower + np.random.random() * (upper - lower)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'centroids' is not defined"
     ]
    }
   ],
   "source": [
    "centroids[0][0] #= \\\n",
    "#                     lower + np.random.random() * (upper - lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(-1,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[1].vector[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower[0] = min(lower[0], words[1].vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower[i] = min(lower[i], words[j].vector[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(5):\n",
    "    for i in range(5):\n",
    "        upper[i] = max([upper[i], words[j].vector[i]])\n",
    "        lower[i] = min([lower[i], words[j].vector[i]])\n",
    "    print(j, words[j].vector[0:5],'\\n', upper[0:5],'\\n', lower[0:5],'\\n', '\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([0,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w[1] = max(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in enumerate(words[2].vector): print(i,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(words[0]['vector'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = '0.53533'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['animals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "]\n",
    "\n",
    "\n",
    "animal = open('animals').read().split('\\n')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in animals:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = animals.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Computation\n",
    "\n",
    "> (2) Vary the value of k from 1 to 10 and compute the precision, recall, and F-score for each set of clusters. Plot k in the horizontal axis and precision, recall and F-score in the vertical axis in the same plot. (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize\n",
    "\n",
    "> (3) Now re-run the k-means clustering algorithm you implemented in part (1) but normalise each feature vector to unit L2 length before computing Euclidean distances. Vary the value of k from 1 to 10 and compute the precision, recall, and F-score for each set of clusters. Plot k in the horizontal axis and precision, recall and F-score in the vertical axis in the same plot. (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manhattan Distance\n",
    "\n",
    "> (4) Now re-run the k-means clustering algorithm you implemented in part (1) but this time use Manhattan distance over the unnormalised feature vectors. Vary the value of k from 1 to 10\n",
    "and compute the precision, recall, and F-score for each set of clusters. Plot k in the horizontal axis and precision, recall and F-score in the vertical axis in the same plot. (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Manhattan Distance\n",
    "\n",
    "> (5) Now re-run the k-means clustering algorithm you implemented in part (1) but this time use Manhattan distance with L2 normalised feature vectors. Vary the value of k from 1 to 10 and\n",
    "compute the precision, recall, and F-score for each set of clusters. Plot k in the horizontal axis and precision, recall and F-score in the vertical axis in the same plot. (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cosine Similarity\n",
    "\n",
    "> (6) Now re-run the k-means clustering algorithm you implemented in part (1) but this time use cosine similarity as the distance (similarity) measure.Vary the value of k from 1 to 10 andcompute the precision, recall, and F-score for each set of clusters. Plot k in the horizontal axis and precision, recall and F-score in the vertical axis in the same plot. (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare and Discuss\n",
    "\n",
    "> (7) Comparing the different clusterings you obtained in (2)-(6) discuss what is the best setting for k-means clustering for this dataset. (20 marks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
