{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP 527: Implementing the k-means clustering algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In the assignment, you are required to cluster words belonging to four categories: animals, countries, fruits and veggies. The words are arranged into four different files. The first entry in each line is a word followed by 300 features (word embedding) describing the meaning of that word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    " \n",
    "> (1) Implement the k-means clustering algorithm with Euclidean distance to cluster the instances into k clusters. (30 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word():\n",
    "    \"\"\"Object class for a categorized word with data vector.\"\"\"\n",
    "    \n",
    "    def __init__(self, name, vector, category):\n",
    "        self.name = name\n",
    "        self.vector = vector\n",
    "        self.category = category\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'word: {self.name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(list_of_filenames):\n",
    "    \"\"\"Read in data.\"\"\"\n",
    "\n",
    "    collection = []\n",
    "\n",
    "    for filename in list_of_filenames:\n",
    "        data = open(filename).read().split('\\n')[:-1]\n",
    "\n",
    "        for word_data in data:\n",
    "            split = word_data.split(' ')\n",
    "            name = split[0]\n",
    "            raw_list = split[1:]\n",
    "\n",
    "            floats = []\n",
    "            for x_string in raw_list:\n",
    "                floats.append(float(x_string))\n",
    "\n",
    "            vector = np.array(floats)\n",
    "\n",
    "            collection.append( Word(name, vector, filename))\n",
    "\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329\n"
     ]
    }
   ],
   "source": [
    "categories = ['animals', 'countries', 'fruits', 'veggies']\n",
    "words = read_data(categories)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "animals 50\n",
      "countries 161\n",
      "fruits 58\n",
      "veggies 60\n"
     ]
    }
   ],
   "source": [
    "category = {}\n",
    "for c in categories:\n",
    "    category[c] = []\n",
    "    for w in words:\n",
    "        if w.category == c:\n",
    "            category[c].append(w)\n",
    "    print(c, len(category[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words:\n",
    "    if w.vector.shape != words[0].vector.shape:\n",
    "        print('ERROR', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(u, v):\n",
    "    \"\"\"Return Euclidean distance between two np.array vectors.\"\"\"\n",
    "\n",
    "    return np.sqrt( (u - v).dot( u - v ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(u, v):\n",
    "    \"\"\"Return Manhattan distance between two np.array vectors.\"\"\"\n",
    "\n",
    "    w = u - v\n",
    "    distance = 0\n",
    "    for x in w:\n",
    "        distance += abs(x)\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(u, v):\n",
    "    \"\"\"Return Cosine similarity of two np.array vectors.\"\"\"\n",
    "    \n",
    "    return u.dot(v)/( np.sqrt(u.dot(u)) * np.sqrt(v.dot(v)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(u):\n",
    "    \"\"\"Return normalized vector (ie. parallel vector with unit magnitude).\"\"\"\n",
    "    \n",
    "    return u / np.sqrt( u.dot(u) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.609447771107847"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distance(category['animals'][0].vector, category['fruits'][3].vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans():\n",
    "    \n",
    "    def __init__(self, k = 5, data = words, metric = euclidean_distance, normalize = False, iterations = 10**10, seed = 1):\n",
    "        \"\"\"\n",
    "        Initialize KMeans Model.\n",
    "        \n",
    "        Args:\n",
    "            k (int): number of clusters to divide data into.\n",
    "            data (list): list of dicts which must each include\n",
    "                the keys 'name' (string) and 'vector' (np.ndarray).\n",
    "            metric (function): to measure distance between points.\n",
    "            normalize (Boolean): whether or not to normalize vectors.\n",
    "            iterations (int): when to stop if no convergence.\n",
    "            seed (int32): for reproducible (pseudo-)randomness.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.k = k\n",
    "        self.data = data\n",
    "        self._upperbound, self._lowerbound = self._bounds()\n",
    "        self.seed = seed\n",
    "        self._centroids = self._start()\n",
    "        self._iteration = 0\n",
    "        self.labels = {}\n",
    "    \n",
    "    def _bounds(self):\n",
    "        \"\"\"Find upper and lower bounds of data space.\"\"\"\n",
    "        \n",
    "        upper = np.zeros(len(words[0].vector))\n",
    "        lower = np.zeros(len(words[0].vector))\n",
    "        \n",
    "        for d in data:\n",
    "            for i, x in enumerate(d.vector):\n",
    "                upper[i] = max(upper[i], x)\n",
    "                lower[i] = min(lower[i], x)\n",
    "        \n",
    "        return upper, lower\n",
    "    \n",
    "    def _start(self):\n",
    "        \"\"\"Generate starting positions for k centroids.\"\"\"\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper = np.zeros(len(words[0].vector))\n",
    "lower = np.zeros(len(words[0].vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = words\n",
    "for d in data:\n",
    "    for i, x in enumerate(d.vector):\n",
    "        upper[i] = max(upper[i], x)\n",
    "        lower[i] = min(lower[i], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2946 , 0.9564 , 0.92792, 0.85099, 1.2966 , 0.8382 , 0.83656,\n",
       "       0.96064, 0.95663, 0.9745 , 0.99057, 1.0373 , 1.5271 , 0.90659,\n",
       "       1.5421 , 1.0302 , 1.1887 , 0.73925, 0.9368 , 0.97064, 0.94997,\n",
       "       1.3882 , 0.74385, 0.86281, 0.91948, 0.66668, 0.84123, 1.0959 ,\n",
       "       0.88543, 0.77246, 1.4636 , 1.226  , 1.3733 , 1.4071 , 1.0275 ,\n",
       "       1.2237 , 1.0922 , 0.80705, 0.84601, 1.1418 , 1.3081 , 0.86901,\n",
       "       1.0584 , 1.2829 , 0.67847, 0.99822, 0.9105 , 0.64708, 0.88737,\n",
       "       0.9553 , 1.0997 , 0.70873, 0.9406 , 1.0906 , 0.80305, 1.0234 ,\n",
       "       0.98461, 0.96752, 1.0902 , 0.72347, 0.76898, 1.0795 , 0.95018,\n",
       "       0.86595, 1.1526 , 1.0572 , 1.1124 , 0.93094, 0.61421, 1.0535 ,\n",
       "       0.79016, 1.0957 , 0.90486, 1.065  , 1.0284 , 1.0057 , 0.73638,\n",
       "       0.97551, 0.98087, 1.0967 , 0.93825, 1.1122 , 0.96254, 0.97279,\n",
       "       0.41297, 0.95982, 1.0984 , 0.92698, 1.172  , 1.2084 , 0.77948,\n",
       "       1.1452 , 0.8467 , 0.87888, 1.1526 , 0.93815, 0.57699, 0.98814,\n",
       "       1.0946 , 0.82528, 0.88191, 0.96237, 1.9523 , 0.96996, 0.83137,\n",
       "       0.70555, 0.8964 , 1.8189 , 0.70985, 0.91871, 0.91786, 0.89984,\n",
       "       1.1759 , 0.94643, 0.90007, 0.88469, 0.87885, 1.1444 , 0.7504 ,\n",
       "       0.88335, 0.82192, 1.1676 , 0.99858, 1.365  , 1.3185 , 1.1301 ,\n",
       "       0.90019, 0.95717, 1.1325 , 0.98241, 0.92621, 0.9499 , 0.84222,\n",
       "       1.2794 , 1.0527 , 0.69574, 0.92354, 1.2495 , 1.0377 , 0.88403,\n",
       "       1.0792 , 0.66711, 0.73535, 1.1041 , 0.99739, 1.2672 , 1.0648 ,\n",
       "       1.1364 , 1.6318 , 0.97668, 0.89883, 0.72885, 1.204  , 1.2656 ,\n",
       "       1.0137 , 0.63753, 1.097  , 1.0031 , 1.1669 , 0.83962, 0.92162,\n",
       "       0.93542, 0.77049, 1.0165 , 1.2073 , 1.1233 , 0.75492, 0.7058 ,\n",
       "       0.82064, 1.0748 , 0.9542 , 1.1289 , 0.98208, 1.018  , 0.75292,\n",
       "       1.3159 , 0.93343, 1.0933 , 1.2331 , 1.2127 , 0.83409, 0.76957,\n",
       "       0.67277, 0.61054, 1.3231 , 0.96343, 0.85939, 1.0866 , 1.0905 ,\n",
       "       0.81769, 1.0516 , 0.81978, 1.118  , 1.4643 , 1.1123 , 1.1043 ,\n",
       "       1.2074 , 0.72533, 0.84594, 0.84756, 0.63665, 0.79637, 1.0284 ,\n",
       "       0.946  , 0.94733, 1.0659 , 1.1583 , 0.89693, 1.0215 , 0.96993,\n",
       "       0.96165, 1.0352 , 1.0752 , 1.1285 , 0.88552, 1.0787 , 1.1573 ,\n",
       "       0.97981, 1.1062 , 0.99618, 0.82513, 0.73659, 0.94259, 1.3621 ,\n",
       "       0.83081, 0.7402 , 1.3532 , 1.1323 , 1.0791 , 1.1848 , 1.0092 ,\n",
       "       1.1219 , 1.2199 , 0.96239, 1.1343 , 0.81184, 0.86935, 1.0292 ,\n",
       "       0.83851, 1.2081 , 0.97138, 0.96013, 1.0348 , 0.89069, 0.78453,\n",
       "       1.0905 , 0.94694, 1.0412 , 1.2827 , 1.2319 , 0.9601 , 0.85295,\n",
       "       1.1226 , 1.0658 , 0.81882, 0.80299, 1.1699 , 1.3204 , 0.83804,\n",
       "       1.1649 , 1.0024 , 0.97398, 0.89566, 0.88145, 0.69076, 1.2396 ,\n",
       "       0.89303, 0.82595, 0.74358, 0.82088, 0.97774, 0.82259, 1.3024 ,\n",
       "       0.64152, 0.87353, 0.77842, 1.0811 , 0.94545, 0.61856, 0.75493,\n",
       "       1.1964 , 0.82569, 1.0708 , 1.2734 , 0.97686, 0.88114, 0.69968,\n",
       "       0.82081, 0.83838, 0.82891, 0.9624 , 1.0971 , 1.0368 , 1.1287 ,\n",
       "       1.0034 , 0.84407, 0.97871, 0.77613, 0.86687, 0.98643])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.99684, -0.91587, -1.0514 , -1.4107 , -0.88439, -1.6586 ,\n",
       "       -2.8027 , -0.95706, -1.0216 , -2.0161 , -1.3544 , -0.71916,\n",
       "       -0.78765, -1.306  , -0.85387, -0.95628, -0.99129, -1.2773 ,\n",
       "       -0.97502, -0.74652, -0.88368, -1.1614 , -0.68309, -0.79758,\n",
       "       -0.9627 , -1.0844 , -1.0948 , -1.1589 , -0.8113 , -0.76359,\n",
       "       -1.6845 , -0.91243, -0.84475, -0.89747, -0.4943 , -0.86348,\n",
       "       -1.084  , -0.85391, -0.93993, -0.74393, -0.55972, -0.89634,\n",
       "       -1.1886 , -1.0417 , -0.74994, -0.82764, -0.89737, -1.0151 ,\n",
       "       -1.038  , -1.1633 , -0.84163, -0.93281, -0.81178, -0.60436,\n",
       "       -1.4898 , -1.1582 , -1.1715 , -1.0008 , -0.5402 , -1.1432 ,\n",
       "       -0.98529, -1.1117 , -1.0757 , -0.7376 , -1.3685 , -0.75747,\n",
       "       -0.84723, -0.87765, -1.2229 , -0.79086, -1.3877 , -1.0092 ,\n",
       "       -0.83267, -0.72224, -0.59768, -0.81945, -0.92068, -0.82162,\n",
       "       -0.99162, -0.94463, -0.86352, -1.4489 , -0.75855, -1.5452 ,\n",
       "       -1.3396 , -1.2483 , -0.97945, -1.5953 , -1.011  , -1.2461 ,\n",
       "       -1.2257 , -1.1625 , -1.1626 , -1.1008 , -0.95518, -1.2982 ,\n",
       "       -2.4825 , -1.2253 , -0.849  , -1.3536 , -1.0488 , -1.1533 ,\n",
       "       -0.87848, -1.0116 , -1.3063 , -0.92195, -0.73963, -1.2438 ,\n",
       "       -0.81636, -0.82454, -1.193  , -1.1568 , -1.0567 , -0.98007,\n",
       "       -0.9885 , -0.97494, -0.69393, -0.70838, -0.87334, -0.97566,\n",
       "       -0.74901, -1.1262 , -0.96819, -1.0594 , -1.0716 , -0.82812,\n",
       "       -0.88379, -0.74833, -0.91739, -0.67086, -1.1321 , -0.798  ,\n",
       "       -0.98757, -0.80482, -0.90899, -0.88385, -0.71565, -1.0193 ,\n",
       "       -0.75369, -0.79681, -1.1792 , -0.8314 , -1.564  , -0.9278 ,\n",
       "       -0.71959, -1.1444 , -0.71172, -0.69114, -0.81473, -1.3403 ,\n",
       "       -1.0159 , -0.91102, -0.92083, -0.90659, -1.0076 , -1.1372 ,\n",
       "       -1.1312 , -0.88716, -0.97427, -1.0982 , -1.2221 , -0.93301,\n",
       "       -0.86914, -0.84569, -0.9837 , -1.4909 , -1.4789 , -0.93089,\n",
       "       -0.7015 , -0.88056, -0.77024, -0.80533, -0.96787, -0.58455,\n",
       "       -0.85994, -0.78392, -0.62797, -1.1307 , -0.99599, -1.0411 ,\n",
       "       -0.73647, -0.88076, -0.95817, -0.89251, -0.8938 , -0.88585,\n",
       "       -1.1962 , -0.92342, -0.74795, -1.1933 , -0.91546, -0.93474,\n",
       "       -0.96861, -1.0795 , -0.97364, -1.1307 , -0.97609, -0.97853,\n",
       "       -0.69605, -0.91287, -1.1482 , -1.0436 , -0.90827, -1.0784 ,\n",
       "       -0.77245, -1.0365 , -1.0948 , -1.1297 , -0.80641, -0.98868,\n",
       "       -0.87361, -1.0705 , -1.337  , -1.1653 , -1.2039 , -1.0141 ,\n",
       "       -1.2458 , -0.94577, -1.1628 , -1.0464 , -0.97716, -1.0026 ,\n",
       "       -1.1883 , -0.82496, -3.3685 , -1.3663 , -1.1115 , -0.85797,\n",
       "       -0.88826, -0.88216, -0.94121, -0.64513, -0.73379, -0.7781 ,\n",
       "       -0.78637, -1.1676 , -0.69501, -0.71333, -1.0983 , -0.68578,\n",
       "       -1.0725 , -0.77263, -1.0088 , -0.83368, -0.7965 , -1.0616 ,\n",
       "       -0.8616 , -0.91225, -1.0756 , -0.55194, -0.94513, -0.97006,\n",
       "       -1.0195 , -0.80576, -0.84048, -1.1078 , -1.0822 , -1.0624 ,\n",
       "       -0.82553, -0.74165, -0.8332 , -1.2322 , -0.72877, -1.1183 ,\n",
       "       -0.72136, -0.95746, -1.5004 , -1.0999 , -0.91913, -0.78202,\n",
       "       -0.8868 , -0.68878, -1.1718 , -1.2295 , -0.91957, -0.9863 ,\n",
       "       -0.96703, -1.5811 , -1.0325 , -1.0889 , -1.194  , -0.87194,\n",
       "       -0.95356, -0.77222, -0.82563, -1.0934 , -1.2329 , -1.1039 ,\n",
       "       -1.1125 , -0.93533, -0.88846, -0.98153, -1.1604 , -0.87948,\n",
       "       -0.82882, -1.0541 , -0.84602, -1.0109 , -0.84361, -0.89242])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(-1,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08111"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47727"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[1].vector[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower[0] = min(lower[0], words[1].vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08111"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower[i] = min(lower[i], words[j].vector[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'min(iterable, *[, default=obj, key=func]) -> value\\nmin(arg1, arg2, *args, *[, key=func]) -> value\\n\\nWith a single iterable argument, return its smallest item. The\\ndefault keyword-only argument specifies an object to return if\\nthe provided iterable is empty.\\nWith two or more arguments, return the smallest argument.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.08111  -0.50285  -0.055975  0.45965  -0.30271 ] \n",
      " [0.08111 0.      0.      0.45965 0.     ] \n",
      " [ 0.       -0.50285  -0.055975  0.       -0.30271 ] \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "1 [ 0.47727 -0.91587 -0.2977  -0.22489  0.55337] \n",
      " [0.47727 0.      0.      0.45965 0.55337] \n",
      " [ 0.      -0.91587 -0.2977  -0.22489 -0.30271] \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "2 [-0.33575  0.38897 -0.41929 -0.33219  0.5317 ] \n",
      " [0.47727 0.38897 0.      0.45965 0.55337] \n",
      " [-0.33575 -0.91587 -0.41929 -0.33219 -0.30271] \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "3 [ 0.2111   0.21763 -0.52638 -0.42277  0.84672] \n",
      " [0.47727 0.38897 0.      0.45965 0.84672] \n",
      " [-0.33575 -0.91587 -0.52638 -0.42277 -0.30271] \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "4 [ 0.08111  -0.50285  -0.055975  0.45965  -0.30271 ] \n",
      " [0.47727 0.38897 0.      0.45965 0.84672] \n",
      " [-0.33575 -0.91587 -0.52638 -0.42277 -0.30271] \n",
      " \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for j in range(5):\n",
    "    for i in range(5):\n",
    "        upper[i] = max([upper[i], words[j].vector[i]])\n",
    "        lower[i] = min([lower[i], words[j].vector[i]])\n",
    "    print(j, words[j].vector[0:5],'\\n', upper[0:5],'\\n', lower[0:5],'\\n', '\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.12452"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([0,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "w[1] = max(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -0.33575\n",
      "1 0.38897\n",
      "2 -0.41929\n",
      "3 -0.33219\n",
      "4 0.5317\n",
      "5 -0.25839\n",
      "6 -2.3869\n",
      "7 -0.43443\n",
      "8 -0.3976\n",
      "9 -0.99356\n",
      "10 0.47093\n",
      "11 -0.16265\n",
      "12 -0.13474\n",
      "13 -1.306\n",
      "14 0.34694\n",
      "15 0.1215\n",
      "16 -0.15811\n",
      "17 -0.011231\n",
      "18 -0.4656\n",
      "19 -0.18031\n",
      "20 0.026682\n",
      "21 -0.028445\n",
      "22 -0.44228\n",
      "23 0.20955\n",
      "24 0.044307\n",
      "25 0.27514\n",
      "26 -0.2314\n",
      "27 -0.10864\n",
      "28 -0.0087113\n",
      "29 0.20522\n",
      "30 0.36109\n",
      "31 -0.35431\n",
      "32 0.25217\n",
      "33 0.26608\n",
      "34 0.11942\n",
      "35 -0.21606\n",
      "36 0.073164\n",
      "37 0.25023\n",
      "38 0.24612\n",
      "39 0.20797\n",
      "40 -0.18702\n",
      "41 -0.038054\n",
      "42 0.23604\n",
      "43 0.42484\n",
      "44 0.10187\n",
      "45 0.058443\n",
      "46 -0.60782\n",
      "47 -0.52279\n",
      "48 -0.026276\n",
      "49 -0.14402\n",
      "50 0.22169\n",
      "51 -0.1585\n",
      "52 -0.81178\n",
      "53 0.082893\n",
      "54 -0.022136\n",
      "55 -0.12966\n",
      "56 0.17201\n",
      "57 0.62484\n",
      "58 -0.023122\n",
      "59 -0.15704\n",
      "60 -0.41946\n",
      "61 -0.49499\n",
      "62 0.056224\n",
      "63 -0.081352\n",
      "64 0.35428\n",
      "65 0.15145\n",
      "66 -0.26535\n",
      "67 0.10071\n",
      "68 -1.0047\n",
      "69 0.34271\n",
      "70 -0.003079\n",
      "71 0.35994\n",
      "72 0.4007\n",
      "73 0.1518\n",
      "74 0.11983\n",
      "75 -0.30275\n",
      "76 0.13739\n",
      "77 -0.36725\n",
      "78 0.3665\n",
      "79 0.31037\n",
      "80 0.513\n",
      "81 0.20102\n",
      "82 -0.34841\n",
      "83 0.28565\n",
      "84 -0.48071\n",
      "85 0.21667\n",
      "86 -0.37125\n",
      "87 0.60281\n",
      "88 0.099829\n",
      "89 -0.47562\n",
      "90 -0.094234\n",
      "91 -0.19625\n",
      "92 -0.12658\n",
      "93 0.025421\n",
      "94 -0.10805\n",
      "95 -0.95298\n",
      "96 -2.1365\n",
      "97 -0.25989\n",
      "98 0.2901\n",
      "99 -0.14846\n",
      "100 -0.06318\n",
      "101 -0.16572\n",
      "102 0.0073842\n",
      "103 -0.30222\n",
      "104 -0.28538\n",
      "105 0.47556\n",
      "106 0.041736\n",
      "107 -0.15516\n",
      "108 0.39398\n",
      "109 -0.60727\n",
      "110 0.7889\n",
      "111 -0.092844\n",
      "112 0.32725\n",
      "113 -0.19599\n",
      "114 -0.21146\n",
      "115 0.023927\n",
      "116 -0.17896\n",
      "117 -0.065021\n",
      "118 0.52246\n",
      "119 -0.38243\n",
      "120 -0.4467\n",
      "121 0.07913\n",
      "122 0.82286\n",
      "123 0.55868\n",
      "124 0.030237\n",
      "125 -0.3001\n",
      "126 0.48222\n",
      "127 0.54899\n",
      "128 -0.3224\n",
      "129 -0.67086\n",
      "130 -0.61622\n",
      "131 0.066708\n",
      "132 0.30572\n",
      "133 0.01517\n",
      "134 -0.52623\n",
      "135 0.15352\n",
      "136 -0.66473\n",
      "137 -0.2077\n",
      "138 0.25136\n",
      "139 0.36206\n",
      "140 -0.22424\n",
      "141 0.00085694\n",
      "142 0.046224\n",
      "143 -0.015066\n",
      "144 -0.32618\n",
      "145 -0.097696\n",
      "146 0.021966\n",
      "147 0.27861\n",
      "148 0.1584\n",
      "149 -0.2021\n",
      "150 0.072365\n",
      "151 -0.1957\n",
      "152 -0.26862\n",
      "153 0.13854\n",
      "154 0.041905\n",
      "155 -0.063822\n",
      "156 -0.32484\n",
      "157 0.055546\n",
      "158 0.28501\n",
      "159 0.67519\n",
      "160 0.30155\n",
      "161 -0.50474\n",
      "162 -0.67976\n",
      "163 0.51983\n",
      "164 0.065695\n",
      "165 0.025286\n",
      "166 -0.096823\n",
      "167 -0.052386\n",
      "168 -0.057766\n",
      "169 0.02108\n",
      "170 -0.24691\n",
      "171 -0.80533\n",
      "172 -0.18712\n",
      "173 0.47986\n",
      "174 -0.45478\n",
      "175 -0.076232\n",
      "176 0.63681\n",
      "177 -0.46249\n",
      "178 0.23123\n",
      "179 0.079812\n",
      "180 -0.61783\n",
      "181 -0.054644\n",
      "182 -0.0015799\n",
      "183 0.1465\n",
      "184 0.053362\n",
      "185 -0.04977\n",
      "186 -0.63187\n",
      "187 -0.11563\n",
      "188 0.38775\n",
      "189 0.10124\n",
      "190 -0.0032881\n",
      "191 0.17987\n",
      "192 -0.06248\n",
      "193 -0.27772\n",
      "194 -0.48288\n",
      "195 -0.37275\n",
      "196 0.61105\n",
      "197 -0.3227\n",
      "198 0.69697\n",
      "199 0.088196\n",
      "200 0.44661\n",
      "201 -0.0065324\n",
      "202 -0.10571\n",
      "203 0.946\n",
      "204 -0.19661\n",
      "205 -0.39961\n",
      "206 0.29346\n",
      "207 0.1364\n",
      "208 0.42281\n",
      "209 -0.45546\n",
      "210 0.54213\n",
      "211 -0.19004\n",
      "212 0.55959\n",
      "213 -0.39935\n",
      "214 0.12659\n",
      "215 -0.29526\n",
      "216 -0.11524\n",
      "217 0.10132\n",
      "218 -0.16572\n",
      "219 0.38628\n",
      "220 -0.25172\n",
      "221 0.30096\n",
      "222 -0.22338\n",
      "223 -0.093883\n",
      "224 -3.1209\n",
      "225 0.07981\n",
      "226 -1.1115\n",
      "227 0.16649\n",
      "228 -0.23107\n",
      "229 -0.12312\n",
      "230 0.20972\n",
      "231 -0.007045\n",
      "232 -0.73021\n",
      "233 -0.47405\n",
      "234 -0.28147\n",
      "235 0.0010118\n",
      "236 0.66102\n",
      "237 -0.011403\n",
      "238 0.031912\n",
      "239 0.50367\n",
      "240 0.51864\n",
      "241 -0.060027\n",
      "242 -0.15285\n",
      "243 0.73159\n",
      "244 -0.5533\n",
      "245 -0.16912\n",
      "246 -0.063391\n",
      "247 0.13858\n",
      "248 0.28878\n",
      "249 0.15076\n",
      "250 -0.22552\n",
      "251 0.28992\n",
      "252 0.54796\n",
      "253 0.1551\n",
      "254 0.51603\n",
      "255 -0.19686\n",
      "256 -0.64146\n",
      "257 0.50649\n",
      "258 0.70221\n",
      "259 -0.21417\n",
      "260 0.35252\n",
      "261 -0.29347\n",
      "262 -0.19962\n",
      "263 -0.055284\n",
      "264 -0.10027\n",
      "265 0.3333\n",
      "266 0.49459\n",
      "267 0.17876\n",
      "268 -0.041699\n",
      "269 0.46649\n",
      "270 -0.3172\n",
      "271 -0.32616\n",
      "272 0.12663\n",
      "273 -0.4367\n",
      "274 -0.54299\n",
      "275 -0.10077\n",
      "276 -0.26449\n",
      "277 0.10524\n",
      "278 -0.325\n",
      "279 -0.28024\n",
      "280 0.49458\n",
      "281 -0.0028948\n",
      "282 -0.86985\n",
      "283 -0.089116\n",
      "284 -0.23145\n",
      "285 -0.40411\n",
      "286 -0.02368\n",
      "287 0.24752\n",
      "288 0.32651\n",
      "289 -0.053385\n",
      "290 -0.11501\n",
      "291 -0.55804\n",
      "292 0.48427\n",
      "293 0.25167\n",
      "294 -0.068426\n",
      "295 0.34227\n",
      "296 0.2684\n",
      "297 -0.14929\n",
      "298 -0.23516\n",
      "299 0.039194\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(words[2].vector): print(i,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.8577e-01, -3.7071e-01, -1.2452e-01, -6.0234e-01,  7.0299e-01,\n",
       "       -1.4603e+00, -5.2778e-01, -3.5435e-02, -4.3165e-01, -1.0401e+00,\n",
       "        2.6789e-01, -2.9573e-01,  8.7415e-01,  2.4446e-01,  3.6380e-01,\n",
       "       -4.8924e-01, -3.0546e-01, -1.1816e+00,  5.2453e-01,  4.4108e-02,\n",
       "        2.6787e-01, -1.5690e-02,  1.3511e-01,  3.5650e-01, -2.2939e-01,\n",
       "        6.1426e-02, -2.4105e-01, -1.1017e-01, -5.1229e-01, -4.0380e-02,\n",
       "        8.3256e-01, -2.5489e-01,  2.3119e-01,  4.6005e-02,  2.5584e-01,\n",
       "       -1.7051e-01, -7.3765e-01,  5.6647e-01, -2.5144e-01,  6.0860e-01,\n",
       "        3.7638e-01, -1.5358e-01,  2.3254e-01,  1.9730e-01, -7.8956e-03,\n",
       "        1.4744e-01, -5.6575e-02, -6.7243e-03,  3.1051e-01, -6.7962e-01,\n",
       "       -1.6831e-01,  2.4753e-01, -2.5611e-01,  6.4161e-01, -7.7726e-01,\n",
       "       -3.1699e-01,  6.5896e-02,  4.7737e-01,  1.3933e-01,  3.9412e-01,\n",
       "        2.4505e-02,  6.0498e-01, -4.8965e-01, -7.2412e-02, -5.4783e-01,\n",
       "       -7.5747e-01, -8.4723e-01,  6.1058e-02, -1.8614e-01, -4.9159e-01,\n",
       "       -4.6957e-01, -4.9365e-01, -1.9644e-01,  1.4703e-01,  2.5994e-01,\n",
       "        4.0746e-01,  3.8054e-01,  2.0153e-01,  1.6043e-01, -2.8710e-01,\n",
       "        3.8908e-01,  3.6102e-01, -2.5516e-01,  2.4678e-01, -3.4257e-01,\n",
       "       -5.2115e-01, -4.9334e-01,  2.2535e-02, -3.2240e-01,  3.7576e-01,\n",
       "       -2.6138e-01, -2.2281e-01, -7.1527e-01, -2.6512e-01, -1.1340e-01,\n",
       "       -4.6857e-04, -2.5335e-01, -3.9165e-01,  1.7922e-01, -9.8354e-02,\n",
       "       -1.8176e-01,  1.6904e-01,  1.5080e+00,  1.3038e-01, -1.4664e-02,\n",
       "        2.7340e-01, -2.1647e-01,  1.1091e-01, -1.6183e-01, -2.8939e-01,\n",
       "        9.1442e-02,  1.6877e-01,  4.5932e-01,  6.0256e-01, -4.4366e-01,\n",
       "       -9.5289e-02,  2.0498e-01, -2.4375e-01, -2.2084e-01,  5.0211e-01,\n",
       "        1.6298e-01, -3.5626e-02, -4.2783e-01, -1.8891e-01, -1.7787e-01,\n",
       "        5.8880e-01, -3.2753e-01, -6.1436e-02, -4.9818e-01, -8.8242e-02,\n",
       "        2.8519e-02, -3.3089e-02,  3.3099e-01, -4.1230e-02,  1.5830e-01,\n",
       "       -1.8678e-02,  5.1118e-01, -3.9184e-01,  4.7844e-01,  3.7132e-01,\n",
       "        4.5753e-01, -7.5318e-02, -8.6503e-01,  5.6242e-03,  9.9739e-01,\n",
       "       -8.7824e-01,  2.3515e-01,  3.0602e-01,  1.1218e+00,  4.0997e-01,\n",
       "       -6.3033e-01,  2.2725e-01,  1.0866e-01, -9.1704e-02,  4.4766e-01,\n",
       "       -8.2066e-02,  2.0854e-01,  1.6936e-02, -3.6940e-02, -8.4784e-01,\n",
       "       -1.7232e-01, -3.1689e-01, -9.0258e-02,  7.8596e-02,  9.0627e-01,\n",
       "        1.3765e-03, -8.1721e-01, -4.1188e-01,  6.0709e-01,  9.2194e-01,\n",
       "       -3.5721e-01,  5.0955e-01, -1.3762e-01, -3.3212e-01,  2.7345e-02,\n",
       "        5.9417e-01,  4.9930e-01,  7.4573e-01, -4.3607e-01, -3.1641e-01,\n",
       "        4.8793e-02,  7.5142e-01, -4.5437e-01, -6.3253e-02, -4.7707e-01,\n",
       "        3.9859e-02, -1.2800e-01, -4.1585e-01,  3.8931e-01,  2.3148e-01,\n",
       "        1.5342e-01,  4.5592e-01, -5.6632e-01, -6.9222e-01, -1.9509e-01,\n",
       "        5.6731e-01,  3.1481e-01, -2.3260e-01, -2.7003e-01, -1.5079e-01,\n",
       "       -2.4694e-02, -2.5741e-01,  6.4546e-02, -1.5701e-01,  4.1378e-01,\n",
       "        3.1802e-01,  1.8095e-01, -1.1297e+00, -1.1413e-01,  2.3702e-02,\n",
       "        1.0995e-01, -6.4466e-02,  2.2153e-01, -3.0573e-01, -3.4883e-01,\n",
       "       -3.7628e-01, -1.2628e-01, -4.6851e-01, -2.6135e-01, -1.2787e-01,\n",
       "        1.7719e-01,  3.3188e-01,  2.3055e-01, -5.8209e-01, -8.8992e-01,\n",
       "        9.2342e-02,  9.6481e-01,  3.3901e-01,  2.2622e-01,  6.7987e-01,\n",
       "       -2.3194e-02, -8.3808e-02,  4.1061e-01, -3.7866e-01, -2.2950e-01,\n",
       "       -2.0297e-02,  6.4927e-02, -1.2502e-01, -4.4204e-01,  4.8715e-01,\n",
       "       -9.5559e-02,  6.1615e-01, -3.7470e-02,  7.7049e-01, -4.6711e-01,\n",
       "        4.7659e-01,  1.6234e-01, -2.1833e-01, -5.7905e-03,  8.5272e-01,\n",
       "       -7.8686e-02,  3.1657e-01,  2.1129e-01,  1.4466e-02,  3.1992e-01,\n",
       "       -8.3385e-02, -2.3255e-01,  5.4719e-01, -2.1005e-01,  2.9976e-01,\n",
       "        8.2239e-02, -3.6287e-01, -2.5548e-01, -4.1357e-01, -1.9872e-01,\n",
       "        9.4535e-01, -1.4025e-01,  5.6538e-02,  1.1061e-01,  3.5359e-01,\n",
       "        2.9881e-01, -3.4140e-01, -5.4899e-01, -1.8242e-01,  2.0288e-01,\n",
       "       -4.9300e-01,  3.8156e-01, -4.0615e-01, -2.9483e-01,  5.2521e-02,\n",
       "        9.0250e-01, -2.1851e-01, -2.2705e-01,  6.9074e-01,  1.5603e-01,\n",
       "        2.0257e-02,  7.6925e-02, -4.2474e-01, -8.1828e-02, -5.3249e-01,\n",
       "       -6.0179e-01, -4.6614e-01,  3.3780e-01, -1.6593e-02,  3.2760e-01,\n",
       "       -9.3397e-02,  1.6020e-02, -5.4729e-03, -8.4361e-01,  8.7304e-02])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(words[0]['vector'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = '0.53533'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53533"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['animals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "]\n",
    "\n",
    "\n",
    "animal = open('animals').read().split('\\n')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for a in animals:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-255a6ca5673f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manimals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manimals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "animals = animals.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Computation\n",
    "\n",
    "> (2) Vary the value of k from 1 to 10 and compute the precision, recall, and F-score for each set of clusters. Plot k in the horizontal axis and precision, recall and F-score in the vertical axis in the same plot. (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize\n",
    "\n",
    "> (3) Now re-run the k-means clustering algorithm you implemented in part (1) but normalise each feature vector to unit L2 length before computing Euclidean distances. Vary the value of k from 1 to 10 and compute the precision, recall, and F-score for each set of clusters. Plot k in the horizontal axis and precision, recall and F-score in the vertical axis in the same plot. (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manhattan Distance\n",
    "\n",
    "> (4) Now re-run the k-means clustering algorithm you implemented in part (1) but this time use Manhattan distance over the unnormalised feature vectors. Vary the value of k from 1 to 10\n",
    "and compute the precision, recall, and F-score for each set of clusters. Plot k in the horizontal axis and precision, recall and F-score in the vertical axis in the same plot. (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Manhattan Distance\n",
    "\n",
    "> (5) Now re-run the k-means clustering algorithm you implemented in part (1) but this time use Manhattan distance with L2 normalised feature vectors. Vary the value of k from 1 to 10 and\n",
    "compute the precision, recall, and F-score for each set of clusters. Plot k in the horizontal axis and precision, recall and F-score in the vertical axis in the same plot. (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cosine Similarity\n",
    "\n",
    "> (6) Now re-run the k-means clustering algorithm you implemented in part (1) but this time use cosine similarity as the distance (similarity) measure.Vary the value of k from 1 to 10 andcompute the precision, recall, and F-score for each set of clusters. Plot k in the horizontal axis and precision, recall and F-score in the vertical axis in the same plot. (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare and Discuss\n",
    "\n",
    "> (7) Comparing the different clusterings you obtained in (2)-(6) discuss what is the best setting for k-means clustering for this dataset. (20 marks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
